---
title: "Test"
author: "Marina"
date: "14/01/2020"
output: 
  pdf_document:
    df_print: default
    fig_height: 4
    fig_width: 5.32
  slidy_presentation:
    df_print: kable
    css: marina.css
    transition: faster
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```



## Quel est le but des analyses statistiques?

Créer un **modèle** (une simplication) qui reproduise le plus fidèlement les données observées dans la réalité à des fins:  
- d'explication  
- de prédiction  

## Modèles statistiques

- Fondamentalement toujours la même chose:  
$Observation_i = PrédictionDuModèle + erreur_i$

### Fit de notre modèle

$Déviation = \sum (Observation - PrédictionDuModèle)^2$


## Exemple basique: la moyenne comme modèle

10 étudiants, nombre de minutes par semaine passées à étudier les stats.

```{r, echo=F }
set.seed(3)
zz <- data.frame(id=paste("p", 1:10, sep=""), minutes=round(rnorm(10, 120, sd=30)))
zz
```

Notre modèle (la moyenne): `r round(mean(zz$minutes))`



```{r, echo=F }
plot(zz$id, zz$minutes, ylim=c(60,180))
abline(a=mean(zz$minutes), b=0, col="red")
text(zz$id, zz$minutes+10, label=as.character(round(zz$minutes-mean(zz$minutes))))
```

## Fit de notre modèle? {.build}

- Déviation, aussi sous le nom "sum of squares (SS) error".  
$\sum(minutes - moyenne)^2$ = `r sum((zz$minutes-mean(zz$minutes))^2)`  
- Les SS augmentent avec le nombre d'observations, alors on divise par N-1  
$\frac{\sum(minutes - moyenne)^2}{N-1}$ = `r round(var(zz$minutes))`  
- C'est à dire la variance.  
- Pour l'avoir dans les unités d'origine, on prend la racine carrée:  
$\sqrt\frac{\sum(minutes - moyenne)^2}{N-1}$ = `r round(sd(zz$minutes))` minutes  
- C'est à dire l'écart type (standard deviation, SD). 

## Un fit plus ou moins bon (+/- variabilité)

<div class="two-column">
```{r, echo=F, out.width="100%"}
plot(zz$id, zz$minutes, ylim=c(0,240))
abline(a=mean(zz$minutes), b=0, col="red")
text(zz$id, zz$minutes+10, label=as.character(round(zz$minutes-mean(zz$minutes))))
```

```{r, echo=F, out.width="100%"}
set.seed(3)
zz1 <- rnorm(10, mean=120, sd=90)
plot(zz$id, zz1, ylim=c(0,240))
abline(a=mean(zz$minutes), b=0, col="red")
text(zz$id, zz1+10, label=as.character(round(zz1-mean(zz$minutes))))
```
</div>

Notre modèle, la moyenne, a un meilleur fit à gauche, il est plus fidèle à la réalité.

## Visuellement

On peut voir ces différences en regardant la distribution des données.

<div class="two-column">
```{r, echo=F, out.width="100%"}
hist(rnorm(1000, mean=120, sd=10), xlim=c(0,250), ylim=c(0,200), main="", breaks =20, xlab="SD=10")
```

```{r, echo=F, out.width="100%"}
hist(rnorm(1000, mean=120, sd=30), xlim=c(0,250), ylim=c(0,200),main="", breaks=20, xlab="SD=30")
```
</div>

## Au delà de notre échantillon

Si l'on prenait 1000 échantillons d'étudiants dans différentes universités:

* Moyenne échantillon 1: 123 minutes  
* Moyenne échantillon 2: 102 minutes  
* Moyenne échantillon 3: 144 minutes  
* ...  
* Moyenne échantillon 100: 118 minutes

## Distribution d'échantillonnage (sampling distribution)

```{r, echo=F, out.width="60%"}
hist(rnorm(1000, mean=120, sd=20), xlim=c(0,250), ylim=c(0,200), main="", xlab="")
abline(v=120, col="red", lwd=4)
```

- Moyenne des moyennes de tous ces échantillons: 120 minutes  
- Moyenne $\mu$ de la population: 120 minutes  

## Variabilité de cette distribution d'échantillonnage

$SE (StandardError) = SD_{MoyennesTousÉchantillons}$

- Indique dans quelle mesure un échantillon est représentatif de la population.  



TEST

## Central limit theorem (Théorème de la limite centrale)

Malheureusement, rarement accès à 1000 échantillons !

$Moyenne_{Population}=\mu = Moyenne_{TousÉchantillons}$

$SD_{Population}=\sigma = SE = \frac{SD_{echantillon}}{\sqrt N}$

On ne connait pas le reste, mais nous avons accès à la SE!

*Note: valable pour échantillons >30*

## Pourquoi est-ce que c'est utile ?

* Mesure de la "représentativité" de notre échantillon par rapport à la population (sans avoir à recueillir 1000 échantillons!)  
* S'applique aux moyennes mais aussi à toutes les autres statistiques (e.g., $\beta$)  

## Intervalles de confiance